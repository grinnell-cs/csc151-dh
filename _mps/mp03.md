---
title: Mini-Project 3
subtitle: Textual analysis
summary: |
  In this assignment, you will develop some basic tools for analyzing
  texts.
collaboration: |
  Each student should submit their own responses to this assignment. You may
  consult other students in the class as you prepare this assignment.  If
  you receive help from anyone, make sure to cite them in your responses.
  You do not need to cite course pages or classroom comments (but it doesn't
  hurt).
link: false
---
One of the many ways in which humanists now employ computers is in analyzing texts.  
That is, they use programs to identify characteristics of texts as a starting point for deeper reflections on those texts.
These initial analyses can be complex---such as identifying sets of words that regularly occur together, which raises issues not only of efficiency but how you segment sets---while others can be more straightforward, such as looking at the frequency of adverbs or adjectives in a text.

## Submitting your work

Note: Please submit your work on this assignment as `text-analysis.rkt`.

In addition, please make sure to submit any text files you rely on with this file, and make sure that you read from files using only the direct file name, not with a full path.

Please provide proper citations for those text files.
You will find that some of them even include citation guidelines at thes tart.

## Part the first: Word counts

As you saw in a recent lab, the tools you already know permit you to count appearances of words in a longer text.
For example, you may have written code to look for a particular set of characters in the books (no, not the componets of strings).
However, as a computer scientist you know that you should write general code.

Document and write a procedure, `(count-words list-of-words filename)` that takes as input a list of words and produces as output a list of lists, each with a word and its frequency.
Note that you should do *case-insensitive* counting; "River", "river", "RIVER", and even "riVer" should all match "River".


```drracket
> (count-words (list "Sam" "Amazing" "Evil" "Funny") "sams-course-reviews.txt")
'(("Sam" 132) ("Amazing" 2) ("Evil" 666) ("Funny" 0))
```

We would recommend that you create some simple sample files so that you can run tests or experiments on them.

*Note*: Think about how it's best to decompose the problem.
What additional procedures would be useful?

*Expectation*: You should read the file only once in a call to `count-words`, no matter how many words are in the list.
You can find how many times you read a file by using `file-to-chars`, `file-to-words`, `file-to-lines`, and `file-to-string` in place of `file->chars`, `file->words`, `file->lines`, and `file->string`.
(You may need to update your `csc151` package to access those new procedures.)

## Part the second: Readability

As you may recall from the previous assignment, there are a number of algorithms for computing the readability of prose.
In that assignment, we used the Dale-Chall readability formula.
Here's an implementation of that formula.

```
;;; (dale-chall-computation difficult-words words sentences) -> real?
;;;   difficult-words : non-negative-integer?
;;;   words : positive-integer?
;;;   sentences : positive-integer?
;;; Compute the Dale-Chall score for a text with the given characteristics
;;; (number of difficult words, number of words, number of sentences).
(define dale-chall-computation
  (lambda (num-difficult-words total-words num-sentences)
    (dale-chall-formula (/ num-difficult-words total-words)
                        (/ total-words num-sentences))))

;;; (dale-chall-formula pdw asl) -> real?
;;;   pdw : real?
;;;   asl : real?
;;; Compute the Dale-Chall score for a text given the percentage
;;; of difficult words and the average sentence length, using the
;;; Dale-Chall formula 
;;;   0.1579 × (pdw × 100) + 0.0496 × asl
;;;   + 3.6365 if the percent of difficult words is at least 5%.
(define dale-chall-formula
  (lambda (pdw asl)
    (+ (* 0.1579 pdw 100)
       (* 0.0496 asl)
       (if (> pdw 0.05) 3.6365 0))))
```

a. To determine whether or not a word is easy, we'll need a list of easy words.
Here's one.

> <http://countwordsworth.com/download/DaleChallEasyWordList.txt>

Define `easy-words` as the words in that file.

Note that you may not be able to just use `file->words` or `file->lines` on that file because of the formatting.
Hence, you may have to do additional work.

b. Write a procedure `(dale-chall-score str)` that takes a string as input, computes the various aspects of the string, and calls `dale-chall-computation` to determine the Dale-Chall score.
You can find some sample texts at the end of this assignment.

For this procedure, you can assume that every period represents a sentence break and that only periods represent sentence breaks.
For this procedure, you can also assume that every space (or sequence of spaces) represents a word break and that only spaces (or sequences of spaces) represent word breaks.

c. Write a procedure `(dale-chall-score-improved str)` that takes a string as input, computes the various aspects of the string, and calls `dale-chall-computation` to determine the Dale-Chall score.

For this procedure, you should use more sophisticated mechanisms for determining sentence breaks and for extracting words.
For example, some periods might not represent the end of a sentence because, say, they are used with an initial.
And some sentences might end with characters other than periods, such as exclamation points or question marks.
Words generally don't include quotation marks or commas or such.
On the other hand, they may include some non-letter values, such as hyphens.

## Part the third: Sentiment analysis

Another common approach to text analysis is called "sentiment analysis".
Broadly, sentiment analysis is intended to determine the writer's overall sentiment in a piece of writing.
Are they happy?  Sad?  Angry?  Enthusiastic?
Rumor has it that Amazon uses sentiment analysis in selecting reviews to prioritize and for other things, too.

The most straightforward form of sentiment analysis involves looking at word frequencies.
A document with more positive than negative words is likely to be interepreted as positive.
A document with more negative than positive words is likely to be interpreted as negative.

Conveniently, there are two long lists of positive and negative
words available to you.

> <http://ptrckprry.com/course/ssd/data/positive-words.txt>

> <http://ptrckprry.com/course/ssd/data/negative-words.txt>

**Please read the notes at the top of those files before you use them.**

a.
Define lists of strings `positive-words` and `negative-words` by reading from those files.
You should be able to get most of the work done using `file->lines` (or `file-to-lines`).
Note, however, that each file begins with a series of lines that start with semicolons.

b. Document and write a procedure, `(posneg str)`, that takes a string as an input and returns 

* `"positive"` if the percent of positive words (on a 0 to 1 scale) is at least 0.05 higher than the percent of negative words;
* `"negative"` if the percent of negative words is at least 5% higher than the percent of positive words; and 
* `"neutral"` in all other cases.

## Part the fourth: Basic gender analysis

a.
Write a procedure, (count-male-pronouns str), that takes a string as input and counts the number of male pronouns ("he", "him", "his") in the string.

Be careful not to count words like "history".

```
;;; (count-male-pronouns str) -> integer?
;;;   str : string
;;; Count how many times that male pronouns appear as
;;; individual words in str.
```

b.
Write a procedure, (count-female-pronouns str), that takes a string as input and counts the number of female pronouns (she, her, hers) in the string.  Once again, you should be careful not to count words like "heroic".

```
;;; (count-female-pronouns str) -> integer?
;;;   str : string
;;; Count how many times that female pronouns appear as
;;; individual words in str.
```

c. 
Choose a book from Project Gutenburg.
Using your two procedures, determine whether the book you chose is more likely to use male pronouns or female pronouns.
Insert the results of your experiments as a comment in your code file.
(You should copy and paste the expressions and results from the interactions pane.  You might then add a few lines of commentary.)
If you deem it appropriate, you might also explore the use of non-gendered pronouns.

## Part the fifth: Wordle assistants

As you may have heard, the game Wordle has experienced a recent surge in popularity.
Wordle bears som similarity to Mastermind.
As you play, you learn letters that belong in a word.
For some letters, you know both the letter and the position.
For other letters, you know that the letter appears somewhere in the string.

As we saw in a recent lab, the file [`/usr/share/dict/words`](words.txt) contains a long list of words in English.

Write a procedure, `(wordle-helper first-char last-char middle-char)`, the finds all the five-letter words in that file that start with `first-char`, end with `last-char`, and have `middle-char` somewhere in the middle.

## Part the sixth: Freestyle

Document and write one non-trivial procedure that does some other kind of textual analysis that you expect would be fun or useful.

Do not write a small variant of any of the procedures above.

Make sure that your procedure makes direct use of regular expressions in some way.

The regular expression should involve at least three different `rex-???` procedures.

## Partial rubric

In grading these assignment, we will look for the following.
We may also identify other characteristics that move your work between levels.
One-star items are required for **R** and above.
Two-star items are required for **M** or above.
Three-star items are required for **E**.

_This rubric may be updated closer to the due date._

### Unit tests

```
[ ] Passes all the one-star unit tests (*)
[ ] Passes all the two-star unit tests (**)
[ ] Passes all the three-star unit tests (***)
```

### General

```
[ ] The Racket file is correctly named (`text-analysis.rkt`) (*)
[ ] The Racket file contains an introductory comment with name, date, 
    assignment, course, and citations (*)
[ ] All associated/referenced files are included (*)
[ ] All associated files are done with the file name, not with a full path (*)
[ ] All the associated files are cited (*)
[ ] The code has been reformatted with Ctrl-I before submitting (*)
[ ] Variables have clear names (**)
[ ] Generally good style, with few stylistic errors (**)
[ ] All procedures are documented and the documentation is (mostly)
    correct (**)
```

### Part one

```
[ ] Avoids reading files more than once (**)
[ ] Decomposes the problem (**)
```

### Part two

```
[ ] 
```

### Part three

```
[ ] Cites the positive-words and negative-words files (*)
[ ] Cites the positive-words and negative-words files according to the
    guidance in those files (**)
```

### Part four

### Part five

### Part six

```
[ ] Includes a procedure (*)
[ ] The procedure achieves something nontrivial (**)
[ ] The procedure uses a new regular expression with at least three of
    the rex procedures (**)
```

### Exemplary / Exceeds expectations

```
[ ] Avoids other expensive repeated work. 
[ ] Appropriately decomposes the problem in part three.
[ ] Particularly interesting procedures in part five.
[ ] In computing the Dale-Chall score, finds words with something more
    clever than "break at spaces".
[ ] In computing the Dale-Chall score, finds sentences with something more
    clever than "break at periods".
```

## Sample definitions for Dale-Chall experiments.

```
; Invented by SamR.  Should be fairly readable.
(define simple-01
  "The lamb says baa.")

; Stolen from Sandra Boynton's _Moo, Baa, La La La_.  Transcribed by SamR (almost from memory).
(define boynton-01
  "A cow says moo.  A sheep says baa.  Three singing pigs say la la la.  No no, you say, that isn't right.  The pigs say oink all day and night.  Rhinoceroses snort and snuff and little dogs go ruff ruff ruff.  Some other dogs go bow wow.  And cats and kittens say meow.  Quack says the duck.  A horse says neigh.  It's quiet now.  What do you say?")
```

## Acknowledgements

The positive and negative words files are the work of Hu, Liu, and Cheng.
See the files themselves and the following papers for additional notes.

Minqing Hu and Bing Liu. "Mining and Summarizing Customer Reviews." 
_Proceedings of the ACM SIGKDD International Conference on Knowledge 
Discovery and Data Mining_ (KDD-2004), Aug 22-25, 2004, Seattle, 
Washington, USA.

Bing Liu, Minqing Hu and Junsheng Cheng. "Opinion Observer: Analyzing 
and Comparing Opinions on the Web." _Proceedings of the 14th 
International World Wide Web conference_ (WWW-2005), May 10-14, 
2005, Chiba, Japan.

